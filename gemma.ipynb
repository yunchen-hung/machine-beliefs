{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1c45fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_on_empiricism = [\n",
    "    'Alex can see things with his eyes. When could Alex see with his eyes for the first time?',\n",
    "    'When there is a sound close by, Alex can hear it. When could Alex hear sounds for the first time?',\n",
    "    'When seeing a red flower and a blue flower, Alex can tell that they are different colors. Alex can tell colors apart. \\\n",
    "    When could Alex tell colors apart for the first time?',\n",
    "    'When there is a car approaching, Alex can tell that the car is getting closer. Alex can tell what is near and what is far. \\\n",
    "    When could Alex tell near and far for the first time?',\n",
    "    'When Alex sees someone hold an object and then drop it, Alex thinks the object will fall. Alex thinks objects will fall if we let go of them.\\\n",
    "     When could Alex think that for the first time?',\n",
    "    'If Alex sees a toy being hidden in a box, he will think the object is still there even though he can no longer see it.\\\n",
    "     When could Alex think that for the first time?',\n",
    "    'If Alex sees two cookies, one with 5 chocolate chips in it and one with 20 chocolate chips in it, he can tell which cookie has more chocolate chips without counting. \\\n",
    "     When could Alex tell which has more for the first time?',\n",
    "    'If Alex sees a turtle that is upside down and struggling to get on its feet, he thinks that he should help the turtle. Alex thinks that helping is the right thing to do. \\\n",
    "    When could Alex think that for the first time?',\n",
    "    'Alex can read books. When could Alex read for the first time? '\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b288c5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yh1242\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import glob\n",
    "\n",
    "# FGNET age progression dataset from kaggle\n",
    "path = kagglehub.dataset_download(\"aiolapo/fgnet-dataset\")\n",
    "\n",
    "age_paths = {'newborn': glob.glob(f\"{path}/**/080A00.JPG\", recursive=True)[0], \"older_infant\": glob.glob(f\"{path}/**/080A01.JPG\", recursive=True)[0],\n",
    "            'toddler': glob.glob(f\"{path}/**/080A02.JPG\", recursive=True)[0], 'preschool_child': glob.glob(f\"{path}/**/080A04.JPG\", recursive=True)[0],\n",
    "            'schoolage_child': glob.glob(f\"{path}/**/080A07.JPG\", recursive=True)[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda3707c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import huggingface_hub\n",
    "huggingface_hub.login('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aab1078",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yh1242\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\yh1242\\.cache\\huggingface\\hub\\models--google--gemma-3-27b-it. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Fetching 12 files: 100%|██████████| 12/12 [08:47<00:00, 43.98s/it]  \n",
      "Loading checkpoint shards: 100%|██████████| 12/12 [00:19<00:00,  1.62s/it]\n",
      "Some parameters are on the meta device because they were offloaded to the disk and cpu.\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.\n",
      "\n",
      "Babies are born with some vision, but it's quite blurry at first. Vision develops rapidly in the first few months. Image 1 shows a very young baby, likely around 3-6 months old, when vision is starting to become more focused and they can begin to track objects and recognize faces. Images 2 and 3 show older children with more developed vision, but the *first* time Alex could see would have been as a baby in image 1.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor, Gemma3ForConditionalGeneration\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "#template from https://huggingface.co/google/gemma-3-27b-it\n",
    "model_id = \"google/gemma-3-27b-it\"\n",
    "\n",
    "model = Gemma3ForConditionalGeneration.from_pretrained(\n",
    "    model_id, device_map=\"auto\"\n",
    ").eval()\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": [{\"type\": \"text\", \"text\": \"You are a human answering questions for a psychology survey.\"}]\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\", \"url\": age_paths['newborn']},\n",
    "          {\"type\": \"image\", \"url\": age_paths['toddler']},\n",
    "          {\"type\": \"image\", \"url\": age_paths['schoolage_child']},\n",
    "          {\"type\": \"text\", \"text\": f'{questions_on_empiricism[0]} Pick from image 1, 2, 3. \\\n",
    "           You must reply with either 1, 2, or 3 and specify the age of the child.'},\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "inputs = processor.apply_chat_template(\n",
    "    messages, add_generation_prompt=True, tokenize=True,\n",
    "    return_dict=True, return_tensors=\"pt\"\n",
    ").to(model.device, dtype=torch.bfloat16)\n",
    "\n",
    "input_len = inputs[\"input_ids\"].shape[-1]\n",
    "\n",
    "with torch.inference_mode():\n",
    "    generation = model.generate(**inputs, max_new_tokens=100, do_sample=False)\n",
    "    generation = generation[0][input_len:]\n",
    "\n",
    "decoded = processor.decode(generation, skip_special_tokens=True)\n",
    "print(decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3689f6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 12/12 [00:22<00:00,  1.88s/it]\n",
      "Some parameters are on the meta device because they were offloaded to the disk and cpu.\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 – Approximately 6-7 years old. \n",
      "\n",
      "Here's my reasoning:\n",
      "\n",
      "The capacity for empathy and understanding the distress of another being, and then acting on a moral imperative to help, develops significantly around 6-7 years old. While babies (image 1) and toddlers (image 2) can show *some* emotional response, it's not the same as consciously understanding the turtle's plight and feeling a sense of obligation to assist. By age 6\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor, Gemma3ForConditionalGeneration\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "#template from https://huggingface.co/google/gemma-3-27b-it\n",
    "model_id = \"google/gemma-3-27b-it\"\n",
    "\n",
    "model = Gemma3ForConditionalGeneration.from_pretrained(\n",
    "    model_id, device_map=\"auto\"\n",
    ").eval()\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": [{\"type\": \"text\", \"text\": \"You are a human answering questions for a psychology survey.\"}]\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\", \"url\": age_paths['newborn']},\n",
    "          {\"type\": \"image\", \"url\": age_paths['toddler']},\n",
    "          {\"type\": \"image\", \"url\": age_paths['schoolage_child']},\n",
    "          {\"type\": \"text\", \"text\": f'{questions_on_empiricism[-2]} Pick from image 1, 2, 3. \\\n",
    "           You must reply with either 1, 2, or 3 and specify the age of the child.'},\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "inputs = processor.apply_chat_template(\n",
    "    messages, add_generation_prompt=True, tokenize=True,\n",
    "    return_dict=True, return_tensors=\"pt\"\n",
    ").to(model.device, dtype=torch.bfloat16)\n",
    "\n",
    "input_len = inputs[\"input_ids\"].shape[-1]\n",
    "\n",
    "with torch.inference_mode():\n",
    "    generation = model.generate(**inputs, max_new_tokens=100, do_sample=False)\n",
    "    generation = generation[0][input_len:]\n",
    "\n",
    "decoded = processor.decode(generation, skip_special_tokens=True)\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aff157b",
   "metadata": {},
   "source": [
    "### use a smaller version of gemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65e3ad88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Device set to use cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'generated_text': [{'role': 'system',\n",
       "     'content': [{'type': 'text',\n",
       "       'text': 'You are a human answering questions for a psychology survey.'}]},\n",
       "    {'role': 'user',\n",
       "     'content': [{'type': 'image',\n",
       "       'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A00.JPG'},\n",
       "      {'type': 'image',\n",
       "       'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A02.JPG'},\n",
       "      {'type': 'image',\n",
       "       'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A07.JPG'},\n",
       "      {'type': 'text',\n",
       "       'text': 'Alex can see things with his eyes. When could Alex see with his eyes for the first time? Pick from image 1, 2, 3.            You must reply with either 1, 2, or 3 and specify the age of the child.'}]},\n",
       "    {'role': 'assistant',\n",
       "     'content': \"Okay, let's analyze this.\\n\\nLooking at the images, **image 1** is the most likely time Alex could have first seen with his eyes. \\n\\nThe child in image 1 is approximately **6 months old**.\"}]}]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "#template from https://huggingface.co/google/gemma-3-1b-it\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"google/gemma-3-1b-it\", device=\"cuda\", torch_dtype=torch.bfloat16)\n",
    "\n",
    "messages = [\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "             \"content\": [{\"type\": \"text\", \"text\": \"You are a human answering questions for a psychology survey.\"}]\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "           \"content\": [\n",
    "            {\"type\": \"image\", \"url\": age_paths['newborn']},\n",
    "          {\"type\": \"image\", \"url\": age_paths['toddler']},\n",
    "          {\"type\": \"image\", \"url\": age_paths['schoolage_child']},\n",
    "          {\"type\": \"text\", \"text\": f'{questions_on_empiricism[0]} Pick from image 1, 2, 3. \\\n",
    "           You must reply with either 1, 2, or 3 and specify the age of the child.'},\n",
    "        ]\n",
    "        },\n",
    "    ],\n",
    "]\n",
    "\n",
    "output = pipe(messages, max_new_tokens=50)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6935327",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Device set to use cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'generated_text': [{'role': 'system',\n",
       "     'content': [{'type': 'text',\n",
       "       'text': 'You are a human answering questions for a psychology survey.'}]},\n",
       "    {'role': 'user',\n",
       "     'content': [{'type': 'image',\n",
       "       'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A00.JPG'},\n",
       "      {'type': 'image',\n",
       "       'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A02.JPG'},\n",
       "      {'type': 'image',\n",
       "       'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A07.JPG'},\n",
       "      {'type': 'text',\n",
       "       'text': 'If Alex sees a turtle that is upside down and struggling to get on its feet, he thinks that he should help the turtle. Alex thinks that helping is the right thing to do.     When could Alex think that for the first time? Pick from image 1, 2, 3.            You must reply with either 1, 2, or 3 and specify the age of the child.'}]},\n",
       "    {'role': 'assistant',\n",
       "     'content': '2\\n\\nChildhood (around 6-8 years old)'}]}]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "#template from https://huggingface.co/google/gemma-3-1b-it\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"google/gemma-3-1b-it\", device=\"cuda\", torch_dtype=torch.bfloat16)\n",
    "\n",
    "messages = [\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "             \"content\": [{\"type\": \"text\", \"text\": \"You are a human answering questions for a psychology survey.\"}]\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "           \"content\": [\n",
    "            {\"type\": \"image\", \"url\": age_paths['newborn']},\n",
    "          {\"type\": \"image\", \"url\": age_paths['toddler']},\n",
    "          {\"type\": \"image\", \"url\": age_paths['schoolage_child']},\n",
    "          {\"type\": \"text\", \"text\": f'{questions_on_empiricism[-2]} Pick from image 1, 2, 3. \\\n",
    "           You must reply with either 1, 2, or 3 and specify the age of the child.'},\n",
    "        ]\n",
    "        },\n",
    "    ],\n",
    "]\n",
    "\n",
    "output = pipe(messages, max_new_tokens=50)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73a9d8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Device set to use cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'generated_text': [{'role': 'system',\n",
       "     'content': [{'type': 'text',\n",
       "       'text': 'You are a human answering questions for a psychology survey.'}]},\n",
       "    {'role': 'user',\n",
       "     'content': [{'type': 'image',\n",
       "       'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A00.JPG'},\n",
       "      {'type': 'image',\n",
       "       'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A02.JPG'},\n",
       "      {'type': 'image',\n",
       "       'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A07.JPG'},\n",
       "      {'type': 'text',\n",
       "       'text': 'If Alex sees two cookies, one with 5 chocolate chips in it and one with 20 chocolate chips in it, he can tell which cookie has more chocolate chips without counting.      When could Alex tell which has more for the first time? Pick from image 1, 2, 3.            You must reply with either 1, 2, or 3 and specify the age of the child.'}]},\n",
       "    {'role': 'assistant', 'content': '2\\n\\nAge 8'}]}]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "#template from https://huggingface.co/google/gemma-3-1b-it\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"google/gemma-3-1b-it\", device=\"cuda\", torch_dtype=torch.bfloat16)\n",
    "\n",
    "messages = [\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "             \"content\": [{\"type\": \"text\", \"text\": \"You are a human answering questions for a psychology survey.\"}]\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "           \"content\": [\n",
    "            {\"type\": \"image\", \"url\": age_paths['newborn']},\n",
    "          {\"type\": \"image\", \"url\": age_paths['toddler']},\n",
    "          {\"type\": \"image\", \"url\": age_paths['schoolage_child']},\n",
    "          {\"type\": \"text\", \"text\": f'{questions_on_empiricism[6]} Pick from image 1, 2, 3. \\\n",
    "           You must reply with either 1, 2, or 3 and specify the age of the child.'},\n",
    "        ]\n",
    "        },\n",
    "    ],\n",
    "]\n",
    "\n",
    "output = pipe(messages, max_new_tokens=50)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "738417b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Device set to use cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'generated_text': [{'role': 'system',\n",
       "     'content': [{'type': 'text',\n",
       "       'text': 'You are a human answering questions for a psychology survey.'}]},\n",
       "    {'role': 'user',\n",
       "     'content': [{'type': 'image',\n",
       "       'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A00.JPG'},\n",
       "      {'type': 'image',\n",
       "       'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A02.JPG'},\n",
       "      {'type': 'image',\n",
       "       'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A07.JPG'},\n",
       "      {'type': 'text',\n",
       "       'text': 'When there is a sound close by, Alex can hear it. When could Alex hear sounds for the first time? Pick from image 1, 2, 3.            You must reply with either 1, 2, or 3 and specify the age of the child.'}]},\n",
       "    {'role': 'assistant', 'content': '2\\n\\nAge 8'}]}]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "#template from https://huggingface.co/google/gemma-3-1b-it\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"google/gemma-3-1b-it\", device=\"cuda\", torch_dtype=torch.bfloat16)\n",
    "\n",
    "messages = [\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "             \"content\": [{\"type\": \"text\", \"text\": \"You are a human answering questions for a psychology survey.\"}]\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "           \"content\": [\n",
    "            {\"type\": \"image\", \"url\": age_paths['newborn']},\n",
    "          {\"type\": \"image\", \"url\": age_paths['toddler']},\n",
    "          {\"type\": \"image\", \"url\": age_paths['schoolage_child']},\n",
    "          {\"type\": \"text\", \"text\": f'{questions_on_empiricism[1]} Pick from image 1, 2, 3. \\\n",
    "           You must reply with either 1, 2, or 3 and specify the age of the child.'},\n",
    "        ]\n",
    "        },\n",
    "    ],\n",
    "]\n",
    "\n",
    "output = pipe(messages, max_new_tokens=50)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b7993e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
