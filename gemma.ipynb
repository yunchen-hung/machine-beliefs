{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1c45fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_on_empiricism = [\n",
    "    'Alex can see things with his eyes. When could Alex see with his eyes for the first time?',\n",
    "    'When there is a sound close by, Alex can hear it. When could Alex hear sounds for the first time?',\n",
    "    'When seeing a red flower and a blue flower, Alex can tell that they are different colors. Alex can tell colors apart. \\\n",
    "    When could Alex tell colors apart for the first time?',\n",
    "    'When there is a car approaching, Alex can tell that the car is getting closer. Alex can tell what is near and what is far. \\\n",
    "    When could Alex tell near and far for the first time?',\n",
    "    'When Alex sees someone hold an object and then drop it, Alex thinks the object will fall. Alex thinks objects will fall if we let go of them.\\\n",
    "     When could Alex think that for the first time?',\n",
    "    'If Alex sees a toy being hidden in a box, he will think the object is still there even though he can no longer see it.\\\n",
    "     When could Alex think that for the first time?',\n",
    "    'If Alex sees two cookies, one with 5 chocolate chips in it and one with 20 chocolate chips in it, he can tell which cookie has more chocolate chips without counting. \\\n",
    "     When could Alex tell which has more for the first time?',\n",
    "    'If Alex sees a turtle that is upside down and struggling to get on its feet, he thinks that he should help the turtle. Alex thinks that helping is the right thing to do. \\\n",
    "    When could Alex think that for the first time?',\n",
    "    'Alex can read books. When could Alex read for the first time? '\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b288c5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yh1242\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import glob\n",
    "\n",
    "path = kagglehub.dataset_download(\"aiolapo/fgnet-dataset\")\n",
    "\n",
    "age_paths = {'newborn': glob.glob(f\"{path}/**/080A00.JPG\", recursive=True)[0], \"older_infant\": glob.glob(f\"{path}/**/080A01.JPG\", recursive=True)[0],\n",
    "            'toddler': glob.glob(f\"{path}/**/080A02.JPG\", recursive=True)[0], 'preschool_child': glob.glob(f\"{path}/**/080A04.JPG\", recursive=True)[0],\n",
    "            'schoolage_child': glob.glob(f\"{path}/**/080A07.JPG\", recursive=True)[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda3707c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import huggingface_hub\n",
    "huggingface_hub.login('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aab1078",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yh1242\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\yh1242\\.cache\\huggingface\\hub\\models--google--gemma-3-27b-it. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Fetching 12 files: 100%|██████████| 12/12 [08:47<00:00, 43.98s/it]  \n",
      "Loading checkpoint shards: 100%|██████████| 12/12 [00:19<00:00,  1.62s/it]\n",
      "Some parameters are on the meta device because they were offloaded to the disk and cpu.\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.\n",
      "\n",
      "Babies are born with some vision, but it's quite blurry at first. Vision develops rapidly in the first few months. Image 1 shows a very young baby, likely around 3-6 months old, when vision is starting to become more focused and they can begin to track objects and recognize faces. Images 2 and 3 show older children with more developed vision, but the *first* time Alex could see would have been as a baby in image 1.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor, Gemma3ForConditionalGeneration\n",
    "import torch\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "model_id = \"google/gemma-3-27b-it\"\n",
    "model = Gemma3ForConditionalGeneration.from_pretrained(\n",
    "    model_id, device_map=\"auto\"\n",
    ").eval()\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": [{\"type\": \"text\", \"text\": \"You are a human answering questions for a psychology survey.\"}]\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\", \"url\": age_paths['newborn']},\n",
    "          {\"type\": \"image\", \"url\": age_paths['toddler']},\n",
    "          {\"type\": \"image\", \"url\": age_paths['schoolage_child']},\n",
    "          {\"type\": \"text\", \"text\": f'{questions_on_empiricism[0]} Pick from image 1, 2, 3. \\\n",
    "           You must reply with either 1, 2, or 3 and specify the age of the child.'},\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "inputs = processor.apply_chat_template(\n",
    "    messages, add_generation_prompt=True, tokenize=True,\n",
    "    return_dict=True, return_tensors=\"pt\"\n",
    ").to(model.device, dtype=torch.bfloat16)\n",
    "\n",
    "input_len = inputs[\"input_ids\"].shape[-1]\n",
    "\n",
    "with torch.inference_mode():\n",
    "    generation = model.generate(**inputs, max_new_tokens=100, do_sample=False)\n",
    "    generation = generation[0][input_len:]\n",
    "\n",
    "decoded = processor.decode(generation, skip_special_tokens=True)\n",
    "print(decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3689f6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 12/12 [00:22<00:00,  1.88s/it]\n",
      "Some parameters are on the meta device because they were offloaded to the disk and cpu.\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 – Approximately 6-7 years old. \n",
      "\n",
      "Here's my reasoning:\n",
      "\n",
      "The capacity for empathy and understanding the distress of another being, and then acting on a moral imperative to help, develops significantly around 6-7 years old. While babies (image 1) and toddlers (image 2) can show *some* emotional response, it's not the same as consciously understanding the turtle's plight and feeling a sense of obligation to assist. By age 6\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor, Gemma3ForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "model_id = \"google/gemma-3-27b-it\"\n",
    "model = Gemma3ForConditionalGeneration.from_pretrained(\n",
    "    model_id, device_map=\"auto\"\n",
    ").eval()\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": [{\"type\": \"text\", \"text\": \"You are a human answering questions for a psychology survey.\"}]\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\", \"url\": age_paths['newborn']},\n",
    "          {\"type\": \"image\", \"url\": age_paths['toddler']},\n",
    "          {\"type\": \"image\", \"url\": age_paths['schoolage_child']},\n",
    "          {\"type\": \"text\", \"text\": f'{questions_on_empiricism[-2]} Pick from image 1, 2, 3. \\\n",
    "           You must reply with either 1, 2, or 3 and specify the age of the child.'},\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "inputs = processor.apply_chat_template(\n",
    "    messages, add_generation_prompt=True, tokenize=True,\n",
    "    return_dict=True, return_tensors=\"pt\"\n",
    ").to(model.device, dtype=torch.bfloat16)\n",
    "\n",
    "input_len = inputs[\"input_ids\"].shape[-1]\n",
    "\n",
    "with torch.inference_mode():\n",
    "    generation = model.generate(**inputs, max_new_tokens=100, do_sample=False)\n",
    "    generation = generation[0][input_len:]\n",
    "\n",
    "decoded = processor.decode(generation, skip_special_tokens=True)\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aff157b",
   "metadata": {},
   "source": [
    "### use a smaller version of gemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e3ad88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Device set to use cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'generated_text': [{'role': 'system',\n",
       "     'content': [{'type': 'text',\n",
       "       'text': 'You are a human answering questions for a psychology survey.'}]},\n",
       "    {'role': 'user',\n",
       "     'content': [{'type': 'image',\n",
       "       'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A00.JPG'},\n",
       "      {'type': 'image',\n",
       "       'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A02.JPG'},\n",
       "      {'type': 'image',\n",
       "       'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A07.JPG'},\n",
       "      {'type': 'text',\n",
       "       'text': 'Alex can see things with his eyes. When could Alex see with his eyes for the first time? Pick from image 1, 2, 3.            You must reply with either 1, 2, or 3 and specify the age of the child.'}]},\n",
       "    {'role': 'assistant',\n",
       "     'content': \"Okay, let's analyze this.\\n\\nLooking at the images, **image 1** is the most likely time Alex could have first seen with his eyes. \\n\\nThe child in image 1 is approximately **6 months old**.\"}]}]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"google/gemma-3-1b-it\", device=\"cuda\", torch_dtype=torch.bfloat16)\n",
    "messages = [\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "             \"content\": [{\"type\": \"text\", \"text\": \"You are a human answering questions for a psychology survey.\"}]\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "           \"content\": [\n",
    "            {\"type\": \"image\", \"url\": age_paths['newborn']},\n",
    "          {\"type\": \"image\", \"url\": age_paths['toddler']},\n",
    "          {\"type\": \"image\", \"url\": age_paths['schoolage_child']},\n",
    "          {\"type\": \"text\", \"text\": f'{questions_on_empiricism[0]} Pick from image 1, 2, 3. \\\n",
    "           You must reply with either 1, 2, or 3 and specify the age of the child.'},\n",
    "        ]\n",
    "        },\n",
    "    ],\n",
    "]\n",
    "\n",
    "output = pipe(messages, max_new_tokens=50)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6935327",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Device set to use cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'generated_text': [{'role': 'system',\n",
       "     'content': [{'type': 'text',\n",
       "       'text': 'You are a human answering questions for a psychology survey.'}]},\n",
       "    {'role': 'user',\n",
       "     'content': [{'type': 'image',\n",
       "       'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A00.JPG'},\n",
       "      {'type': 'image',\n",
       "       'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A02.JPG'},\n",
       "      {'type': 'image',\n",
       "       'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A07.JPG'},\n",
       "      {'type': 'text',\n",
       "       'text': 'If Alex sees a turtle that is upside down and struggling to get on its feet, he thinks that he should help the turtle. Alex thinks that helping is the right thing to do.     When could Alex think that for the first time? Pick from image 1, 2, 3.            You must reply with either 1, 2, or 3 and specify the age of the child.'}]},\n",
       "    {'role': 'assistant',\n",
       "     'content': '2\\n\\nChildhood (around 6-8 years old)'}]}]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"google/gemma-3-1b-it\", device=\"cuda\", torch_dtype=torch.bfloat16)\n",
    "messages = [\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "             \"content\": [{\"type\": \"text\", \"text\": \"You are a human answering questions for a psychology survey.\"}]\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "           \"content\": [\n",
    "            {\"type\": \"image\", \"url\": age_paths['newborn']},\n",
    "          {\"type\": \"image\", \"url\": age_paths['toddler']},\n",
    "          {\"type\": \"image\", \"url\": age_paths['schoolage_child']},\n",
    "          {\"type\": \"text\", \"text\": f'{questions_on_empiricism[-2]} Pick from image 1, 2, 3. \\\n",
    "           You must reply with either 1, 2, or 3 and specify the age of the child.'},\n",
    "        ]\n",
    "        },\n",
    "    ],\n",
    "]\n",
    "\n",
    "output = pipe(messages, max_new_tokens=50)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73a9d8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Device set to use cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'generated_text': [{'role': 'system',\n",
       "     'content': [{'type': 'text',\n",
       "       'text': 'You are a human answering questions for a psychology survey.'}]},\n",
       "    {'role': 'user',\n",
       "     'content': [{'type': 'image',\n",
       "       'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A00.JPG'},\n",
       "      {'type': 'image',\n",
       "       'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A02.JPG'},\n",
       "      {'type': 'image',\n",
       "       'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A07.JPG'},\n",
       "      {'type': 'text',\n",
       "       'text': 'If Alex sees two cookies, one with 5 chocolate chips in it and one with 20 chocolate chips in it, he can tell which cookie has more chocolate chips without counting.      When could Alex tell which has more for the first time? Pick from image 1, 2, 3.            You must reply with either 1, 2, or 3 and specify the age of the child.'}]},\n",
       "    {'role': 'assistant', 'content': '2\\n\\nAge 8'}]}]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"google/gemma-3-1b-it\", device=\"cuda\", torch_dtype=torch.bfloat16)\n",
    "messages = [\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "             \"content\": [{\"type\": \"text\", \"text\": \"You are a human answering questions for a psychology survey.\"}]\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "           \"content\": [\n",
    "            {\"type\": \"image\", \"url\": age_paths['newborn']},\n",
    "          {\"type\": \"image\", \"url\": age_paths['toddler']},\n",
    "          {\"type\": \"image\", \"url\": age_paths['schoolage_child']},\n",
    "          {\"type\": \"text\", \"text\": f'{questions_on_empiricism[6]} Pick from image 1, 2, 3. \\\n",
    "           You must reply with either 1, 2, or 3 and specify the age of the child.'},\n",
    "        ]\n",
    "        },\n",
    "    ],\n",
    "]\n",
    "\n",
    "output = pipe(messages, max_new_tokens=50)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "738417b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Device set to use cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'generated_text': [{'role': 'system',\n",
       "     'content': [{'type': 'text',\n",
       "       'text': 'You are a human answering questions for a psychology survey.'}]},\n",
       "    {'role': 'user',\n",
       "     'content': [{'type': 'image',\n",
       "       'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A00.JPG'},\n",
       "      {'type': 'image',\n",
       "       'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A02.JPG'},\n",
       "      {'type': 'image',\n",
       "       'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A07.JPG'},\n",
       "      {'type': 'text',\n",
       "       'text': 'When there is a sound close by, Alex can hear it. When could Alex hear sounds for the first time? Pick from image 1, 2, 3.            You must reply with either 1, 2, or 3 and specify the age of the child.'}]},\n",
       "    {'role': 'assistant', 'content': '2\\n\\nAge 8'}]}]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"google/gemma-3-1b-it\", device=\"cuda\", torch_dtype=torch.bfloat16)\n",
    "messages = [\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "             \"content\": [{\"type\": \"text\", \"text\": \"You are a human answering questions for a psychology survey.\"}]\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "           \"content\": [\n",
    "            {\"type\": \"image\", \"url\": age_paths['newborn']},\n",
    "          {\"type\": \"image\", \"url\": age_paths['toddler']},\n",
    "          {\"type\": \"image\", \"url\": age_paths['schoolage_child']},\n",
    "          {\"type\": \"text\", \"text\": f'{questions_on_empiricism[1]} Pick from image 1, 2, 3. \\\n",
    "           You must reply with either 1, 2, or 3 and specify the age of the child.'},\n",
    "        ]\n",
    "        },\n",
    "    ],\n",
    "]\n",
    "\n",
    "output = pipe(messages, max_new_tokens=50)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24279478",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alex can see things with his eyes. When could Alex see with his eyes for the first time?\n",
      "[[{'generated_text': [{'role': 'system', 'content': [{'type': 'text', 'text': 'You are a human answering questions for a psychology survey.'}]}, {'role': 'user', 'content': [{'type': 'image', 'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A00.JPG'}, {'type': 'image', 'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A02.JPG'}, {'type': 'image', 'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A07.JPG'}, {'type': 'text', 'text': 'Alex can see things with his eyes. When could Alex see with his eyes for the first time? Pick from image 1, 2, 3.             You must reply with either 1, 2, or 3 and specify the age of the child.'}]}, {'role': 'assistant', 'content': 'Okay, let’s analyze this.\\n\\nBased on the image, Alex can see things with his eyes when he was approximately **6 years old**.'}]}]]\n",
      "\n",
      "\n",
      "When there is a sound close by, Alex can hear it. When could Alex hear sounds for the first time?\n",
      "[[{'generated_text': [{'role': 'system', 'content': [{'type': 'text', 'text': 'You are a human answering questions for a psychology survey.'}]}, {'role': 'user', 'content': [{'type': 'image', 'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A00.JPG'}, {'type': 'image', 'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A02.JPG'}, {'type': 'image', 'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A07.JPG'}, {'type': 'text', 'text': 'When there is a sound close by, Alex can hear it. When could Alex hear sounds for the first time? Pick from image 1, 2, 3.             You must reply with either 1, 2, or 3 and specify the age of the child.'}]}, {'role': 'assistant', 'content': '2\\n\\nAge 8'}]}]]\n",
      "\n",
      "\n",
      "When seeing a red flower and a blue flower, Alex can tell that they are different colors. Alex can tell colors apart.     When could Alex tell colors apart for the first time?\n",
      "[[{'generated_text': [{'role': 'system', 'content': [{'type': 'text', 'text': 'You are a human answering questions for a psychology survey.'}]}, {'role': 'user', 'content': [{'type': 'image', 'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A00.JPG'}, {'type': 'image', 'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A02.JPG'}, {'type': 'image', 'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A07.JPG'}, {'type': 'text', 'text': 'When seeing a red flower and a blue flower, Alex can tell that they are different colors. Alex can tell colors apart.     When could Alex tell colors apart for the first time? Pick from image 1, 2, 3.             You must reply with either 1, 2, or 3 and specify the age of the child.'}]}, {'role': 'assistant', 'content': '2\\n\\n8 years old'}]}]]\n",
      "\n",
      "\n",
      "When there is a car approaching, Alex can tell that the car is getting closer. Alex can tell what is near and what is far.     When could Alex tell near and far for the first time?\n",
      "[[{'generated_text': [{'role': 'system', 'content': [{'type': 'text', 'text': 'You are a human answering questions for a psychology survey.'}]}, {'role': 'user', 'content': [{'type': 'image', 'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A00.JPG'}, {'type': 'image', 'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A02.JPG'}, {'type': 'image', 'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A07.JPG'}, {'type': 'text', 'text': 'When there is a car approaching, Alex can tell that the car is getting closer. Alex can tell what is near and what is far.     When could Alex tell near and far for the first time? Pick from image 1, 2, 3.             You must reply with either 1, 2, or 3 and specify the age of the child.'}]}, {'role': 'assistant', 'content': '2\\n\\nAge 8'}]}]]\n",
      "\n",
      "\n",
      "When Alex sees someone hold an object and then drop it, Alex thinks the object will fall. Alex thinks objects will fall if we let go of them.     When could Alex think that for the first time?\n",
      "[[{'generated_text': [{'role': 'system', 'content': [{'type': 'text', 'text': 'You are a human answering questions for a psychology survey.'}]}, {'role': 'user', 'content': [{'type': 'image', 'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A00.JPG'}, {'type': 'image', 'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A02.JPG'}, {'type': 'image', 'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A07.JPG'}, {'type': 'text', 'text': 'When Alex sees someone hold an object and then drop it, Alex thinks the object will fall. Alex thinks objects will fall if we let go of them.     When could Alex think that for the first time? Pick from image 1, 2, 3.             You must reply with either 1, 2, or 3 and specify the age of the child.'}]}, {'role': 'assistant', 'content': '2\\n\\n6 years old'}]}]]\n",
      "\n",
      "\n",
      "If Alex sees a toy being hidden in a box, he will think the object is still there even though he can no longer see it.     When could Alex think that for the first time?\n",
      "[[{'generated_text': [{'role': 'system', 'content': [{'type': 'text', 'text': 'You are a human answering questions for a psychology survey.'}]}, {'role': 'user', 'content': [{'type': 'image', 'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A00.JPG'}, {'type': 'image', 'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A02.JPG'}, {'type': 'image', 'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A07.JPG'}, {'type': 'text', 'text': 'If Alex sees a toy being hidden in a box, he will think the object is still there even though he can no longer see it.     When could Alex think that for the first time? Pick from image 1, 2, 3.             You must reply with either 1, 2, or 3 and specify the age of the child.'}]}, {'role': 'assistant', 'content': '2\\n\\nChildhood (around 6-8 years old)'}]}]]\n",
      "\n",
      "\n",
      "If Alex sees two cookies, one with 5 chocolate chips in it and one with 20 chocolate chips in it, he can tell which cookie has more chocolate chips without counting.      When could Alex tell which has more for the first time?\n",
      "[[{'generated_text': [{'role': 'system', 'content': [{'type': 'text', 'text': 'You are a human answering questions for a psychology survey.'}]}, {'role': 'user', 'content': [{'type': 'image', 'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A00.JPG'}, {'type': 'image', 'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A02.JPG'}, {'type': 'image', 'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A07.JPG'}, {'type': 'text', 'text': 'If Alex sees two cookies, one with 5 chocolate chips in it and one with 20 chocolate chips in it, he can tell which cookie has more chocolate chips without counting.      When could Alex tell which has more for the first time? Pick from image 1, 2, 3.             You must reply with either 1, 2, or 3 and specify the age of the child.'}]}, {'role': 'assistant', 'content': '2\\n\\nAge 8'}]}]]\n",
      "\n",
      "\n",
      "If Alex sees a turtle that is upside down and struggling to get on its feet, he thinks that he should help the turtle. Alex thinks that helping is the right thing to do.     When could Alex think that for the first time?\n",
      "[[{'generated_text': [{'role': 'system', 'content': [{'type': 'text', 'text': 'You are a human answering questions for a psychology survey.'}]}, {'role': 'user', 'content': [{'type': 'image', 'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A00.JPG'}, {'type': 'image', 'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A02.JPG'}, {'type': 'image', 'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A07.JPG'}, {'type': 'text', 'text': 'If Alex sees a turtle that is upside down and struggling to get on its feet, he thinks that he should help the turtle. Alex thinks that helping is the right thing to do.     When could Alex think that for the first time? Pick from image 1, 2, 3.             You must reply with either 1, 2, or 3 and specify the age of the child.'}]}, {'role': 'assistant', 'content': '2\\n\\nChildhood (around 6-8 years old)'}]}]]\n",
      "\n",
      "\n",
      "Alex can read books. When could Alex read for the first time? \n",
      "[[{'generated_text': [{'role': 'system', 'content': [{'type': 'text', 'text': 'You are a human answering questions for a psychology survey.'}]}, {'role': 'user', 'content': [{'type': 'image', 'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A00.JPG'}, {'type': 'image', 'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A02.JPG'}, {'type': 'image', 'url': 'C:\\\\Users\\\\yh1242\\\\.cache\\\\kagglehub\\\\datasets\\\\aiolapo\\\\fgnet-dataset\\\\versions\\\\1\\\\FGNET\\\\images\\\\080A07.JPG'}, {'type': 'text', 'text': 'Alex can read books. When could Alex read for the first time?  Pick from image 1, 2, 3.             You must reply with either 1, 2, or 3 and specify the age of the child.'}]}, {'role': 'assistant', 'content': 'Okay, let’s look at the image.\\n\\nBased on the image, the child is looking at a book. \\n\\n**1**\\n\\nThe child is 8 years old.'}]}]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"google/gemma-3-1b-it\", device=\"cuda\", torch_dtype=torch.bfloat16)\n",
    "for i in range(len(questions_on_empiricism)):\n",
    "    messages = [\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": [{\"type\": \"text\", \"text\": \"You are a human answering questions for a psychology survey.\"}]\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\", \"url\": age_paths['newborn']},\n",
    "            {\"type\": \"image\", \"url\": age_paths['toddler']},\n",
    "            {\"type\": \"image\", \"url\": age_paths['schoolage_child']},\n",
    "            {\"type\": \"text\", \"text\": f'{questions_on_empiricism[i]} Pick from image 1, 2, 3. \\\n",
    "            You must reply with either 1, 2, or 3 and specify the age of the child.'},\n",
    "            ]\n",
    "            },\n",
    "        ],\n",
    "    ]\n",
    "\n",
    "    output = pipe(messages, max_new_tokens=50)\n",
    "    print(f'{questions_on_empiricism[i]}')\n",
    "    print(output)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021422a9",
   "metadata": {},
   "source": [
    "### Previous version of Gemma (gemma 2)\n",
    "> https://huggingface.co/google/gemma-2-2b-it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da5ae1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 84.56it/s]\n",
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alex can see things with his eyes. When could Alex see with his eyes for the first time?\n",
      "Alex could see with his eyes for the first time around **newborn**, or **around 0-2 months old**.\n",
      "\n",
      "\n",
      "When there is a sound close by, Alex can hear it. When could Alex hear sounds for the first time?\n",
      "The answer is **around 6 to 8 months old**. \n",
      "\n",
      "Here's why: \n",
      "\n",
      "* **Infancy:**  Babies start to develop a sense of hearing around 6 months old.  They begin to distinguish between different sounds\n",
      "\n",
      "\n",
      "When seeing a red flower and a blue flower, Alex can tell that they are different colors. Alex can tell colors apart.     When could Alex tell colors apart for the first time?\n",
      "Alex could tell colors apart for the first time around **6 months old**. \n",
      "\n",
      "Here's why:\n",
      "\n",
      "* **Around 6 months**, babies begin to show a growing ability to discriminate colors. \n",
      "* This development is part of their\n",
      "\n",
      "\n",
      "When there is a car approaching, Alex can tell that the car is getting closer. Alex can tell what is near and what is far.     When could Alex tell near and far for the first time?\n",
      "Alex could tell near and far for the first time around **6 months old**. \n",
      "\n",
      "Here's why:\n",
      "\n",
      "* **Around 6 months:** Babies start to develop object permanence, meaning they understand that things exist even when they can't\n",
      "\n",
      "\n",
      "When Alex sees someone hold an object and then drop it, Alex thinks the object will fall. Alex thinks objects will fall if we let go of them.     When could Alex think that for the first time?\n",
      "Alex could think that for the first time around **9 months old**. \n",
      "\n",
      "Here's why:\n",
      "\n",
      "* **Around 9 months:** Babies begin to develop a strong understanding of cause and effect. They see the world as connected and understand that\n",
      "\n",
      "\n",
      "If Alex sees a toy being hidden in a box, he will think the object is still there even though he can no longer see it.     When could Alex think that for the first time?\n",
      "Alex could start to think that for the first time around **6 months of age**. \n",
      "\n",
      "Here's why:\n",
      "\n",
      "* **Object permanence:** This is the ability to understand that an object continues to exist even when it's out of sight\n",
      "\n",
      "\n",
      "If Alex sees two cookies, one with 5 chocolate chips in it and one with 20 chocolate chips in it, he can tell which cookie has more chocolate chips without counting.      When could Alex tell which has more for the first time?\n",
      "Alex could tell which cookie has more chocolate chips around **3 years old**. \n",
      "\n",
      "Here's why:\n",
      "\n",
      "* **Young children develop number sense:**  By age 3, children start to understand concepts like quantity and compare small numbers.\n",
      "\n",
      "\n",
      "If Alex sees a turtle that is upside down and struggling to get on its feet, he thinks that he should help the turtle. Alex thinks that helping is the right thing to do.     When could Alex think that for the first time?\n",
      "One age at which Alex might start thinking that helping the turtle is the right thing to do is **around 3 years old**. \n",
      "\n",
      "Here's why:\n",
      "\n",
      "* **Cognitive Development:**  Around 3 years old, children develop increasingly sophisticated\n",
      "\n",
      "\n",
      "Alex can read books. When could Alex read for the first time? \n",
      "One age Alex could read for the first time is **3**. \n",
      "\n",
      "It's important to remember that every child develops at their own pace, and some may start reading earlier or later than age 3.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"google/gemma-2-2b-it\", device=\"cuda\", torch_dtype=torch.bfloat16)\n",
    "\n",
    "for i in range(len(questions_on_empiricism)):\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\":  f'{questions_on_empiricism[i]} Please specify ONE age.'}\n",
    "    ]\n",
    "\n",
    "    outputs = pipe(messages, max_new_tokens=50)\n",
    "    assistant_response = outputs[0][\"generated_text\"][-1][\"content\"].strip()\n",
    "    print(f'{questions_on_empiricism[i]}')\n",
    "    print(assistant_response)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5548711e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
